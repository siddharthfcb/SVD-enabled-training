{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these values to add and num hidden layers, \n",
    "# Total layers=hidden+input+output\n",
    "num_hidden_layers=10\n",
    "num_neurons=500\n",
    "#\n",
    "#\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import random_split\n",
    "from matplotlib.pyplot import *\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import time\n",
    "import os\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device=torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://shashikachamod4u.medium.com/excel-csv-to-pytorch-dataset-def496b6bcc1\n",
    "# import os\n",
    "# import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class EQ_dataset(Dataset):\n",
    "    def __init__(self,file_name_inp,file_name_out,file_name_test_in,file_name_test_out):\n",
    "        X=pd.read_csv(file_name_inp,header=None)\n",
    "        y=pd.read_csv(file_name_out,header=None)\n",
    "        \n",
    "        X_test=pd.read_csv(file_name_test_in,header=None)\n",
    "        y_test=pd.read_csv(file_name_test_out,header=None)\n",
    "        \n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        X_test_scaled=scaler.transform(X_test)\n",
    "        \n",
    "        self.X_train= torch.tensor(X_scaled[:],dtype=torch.float32)\n",
    "        self.y_train= torch.tensor(y[:].values,dtype=torch.float32)\n",
    "        self.X_test= torch.tensor(X_test_scaled[:50],dtype=torch.float32) # use it for nep 3\n",
    "        self.y_test= torch.tensor(y_test.values[:50],dtype=torch.float32)\n",
    "#         self.X_test= torch.tensor(X_test_scaled,dtype=torch.float32) \n",
    "#         self.y_test= torch.tensor(y_test.values,dtype=torch.float32)\n",
    "#         print(np.shape(self.X_train))\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_train[idx], self.y_train[idx]\n",
    "    \n",
    "    \n",
    "# EQ_set=EQ_dataset('IO_files/Input_real_eq_all_non_lin_large_accel_noPGA.csv','IO_files/Output_real_eq_all_non_lin_large_accel.csv','IO_files/ValidationX6_accel_noPGA.csv','IO_files/ValidationY6_accel.csv')\n",
    "EQ_set=EQ_dataset('IO_files/Input_real_eq_all_non_lin_large_accel_noPGA.csv','IO_files/Output_real_eq_all_non_lin_large_accel.csv','IO_files/ValidationX_nep3_accel.csv','IO_files/ValidationY_nep3_accel.csv')\n",
    "splitsize=0.1\n",
    "train_set, val_set= random_split(EQ_set, [int(np.ceil((1-splitsize)*len(EQ_set))), int(np.floor(splitsize*len(EQ_set)))])\n",
    "# splitsize=0.1\n",
    "# train_set, val_set= random_split(train_val_set, [int((1-splitsize)*len(train_val_set)), int(splitsize*len(train_val_set))])\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=50, shuffle=True, num_workers=50)\n",
    "val_loader = torch.utils.data.DataLoader(val_set,batch_size=50, shuffle=True, num_workers=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_out=len(EQ_set.y_test.T)\n",
    "num_inputs=len(EQ_set.X_test.T)\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self,num_neurons,num_hidden_layers,num_inputs,num_out):\n",
    "        super(SimpleNet, self).__init__() # takes the nn.module as super\n",
    "        \n",
    "        self.num_inputs=num_inputs\n",
    "        self.num_out=num_out\n",
    "        \n",
    "        self.num_neurons=num_neurons\n",
    "        self.num_hidden_layers=num_hidden_layers\n",
    "        \n",
    "        \n",
    "        self.fc0 = nn.Linear(num_inputs, num_neurons) # first layer\n",
    "        \n",
    "        for ct in range(1,num_hidden_layers+1):\n",
    "            exec(\"self.fc%d = nn.Linear(num_neurons, num_neurons)\"%ct)\n",
    "        exec(\"self.fc%d = nn.Linear(num_neurons, num_out)\"%(ct+1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x\n",
    "        for ct in np.arange(0,self.num_hidden_layers+1):\n",
    "            x=eval('F.relu(self.fc%d(x))'%ct)\n",
    "#             print('F.relu(self.fc%d(x))'%ct)\n",
    "#             print(ct)\n",
    "#             print(x.shape)\n",
    "#             print(x)\n",
    "        x = eval('self.fc%d(x)'%(ct+1))\n",
    "#         print('self.fc%d(x)'%(ct+1))\n",
    "#         print(ct+1)\n",
    "#         print(x.shape)\n",
    "#         print(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "simplenet = SimpleNet(num_neurons,num_hidden_layers,num_inputs,num_out)\n",
    "print(simplenet)\n",
    "simplenet.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_epochs=200\n",
    "tol=0.2\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "def loss_function_custom(output, labels):\n",
    "    y=labels\n",
    "    y_predict=output\n",
    "    return loss_function(y[:,1]/torch.mean(y[:,1]),y_predict[:,1]/torch.mean(y[:,1]))+loss_function(y[:,0]/torch.mean(y[:,0]),y_predict[:,0]/torch.mean(y[:,0]))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#optimizer = torch.optim.SGD(simplenet.parameters(), lr=1e-4, momentum=0.9)\n",
    "#optimizer = torch.optim.Adam(simplenet.parameters(), lr=1e-4, )\n",
    "optimizer = torch.optim.Adam(simplenet.parameters(), lr=1e-4, )\n",
    "\n",
    "elapsed_time_fl=0\n",
    "\n",
    "check =0\n",
    "\n",
    "for epoch in range(N_epochs):\n",
    "    print('####################################################################################################')\n",
    "    start = time.time()\n",
    "    train_loss = 0.0\n",
    "    val_loss=0.0\n",
    "    simplenet.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = simplenet(inputs)\n",
    "        loss = loss_function(outputs, labels)  \n",
    "#         loss = loss_function_custom(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "\n",
    "    \n",
    "    simplenet.eval() \n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = simplenet(inputs)\n",
    "#         loss = loss_function(outputs, labels)\n",
    "        loss = loss_function_custom(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "    print(\"Epoch: {} Train Loss: {} Val Loss: {}\".format(epoch,train_loss/len(train_loader),val_loss/len(val_loader)))\n",
    "    if epoch==0:\n",
    "        train_loss_prev=train_loss/len(train_loader)\n",
    "        val_loss_prev=val_loss/len(val_loader)\n",
    "        \n",
    "    del_train_loss=train_loss_prev-train_loss/len(train_loader)\n",
    "    del_val_loss=val_loss_prev-val_loss/len(val_loader)\n",
    "    \n",
    "    train_loss_prev=train_loss/len(train_loader)\n",
    "    val_loss_prev=val_loss/len(val_loader)\n",
    "    print('check=',check)\n",
    "    print('Change in train loss=',del_train_loss)\n",
    "    print('Change in val loss=',del_val_loss)\n",
    "    elapsed_time_fl = elapsed_time_fl+(time.time() - start) \n",
    "    print(\"Elapsed Time:\",elapsed_time_fl)\n",
    "    print('####################################################################################################')\n",
    "    if del_val_loss<tol*np.abs(del_train_loss):\n",
    "        check+=1\n",
    "    if check>2 and del_val_loss>tol*np.abs(del_train_loss):\n",
    "        check=0\n",
    "    if check>3:\n",
    "        print('Overfitting')\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
